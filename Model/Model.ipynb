{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006201fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Building SVM model...\n",
      "Building Neural Network model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LLM Recommendation System ---\n",
      "\n",
      "Please rate the importance of the following factors (0-10):\n",
      "\n",
      "Importance of performance in different categories (0-10):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 470\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# Run the system\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 470\u001b[0m     svm_model, tf_model, svm_scaler, tf_scaler, tf_encoder, feature_cols, all_data \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# Create a simple Flask API for the LLM recommendation system\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_flask_api\u001b[39m():\n",
      "Cell \u001b[1;32mIn[1], line 430\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    427\u001b[0m tf_model, tf_scaler, tf_encoder, tf_feature_cols, history \u001b[38;5;241m=\u001b[39m build_nn_model(all_data)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m user_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# Get recommendations\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating recommendations...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 314\u001b[0m, in \u001b[0;36mget_user_input\u001b[1;34m(feature_cols)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImportance of performance in different categories (0-10):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMLU(General)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m feature_cols:\n\u001b[1;32m--> 314\u001b[0m     general_knowledge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeneral knowledge: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     user_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMLU(General)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m general_knowledge \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Scale to 0-1\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPQA(Reasoning)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m feature_cols:\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import io\n",
    "\n",
    "# Function to convert string percentages to floats\n",
    "def convert_percentage(value):\n",
    "    if isinstance(value, str):\n",
    "        if '%' in value:\n",
    "            return float(value.strip('%')) / 100\n",
    "    return value\n",
    "\n",
    "# Function to clean and convert cost data\n",
    "def clean_cost(value):\n",
    "    if isinstance(value, str):\n",
    "        if value == \"NULL\":\n",
    "            return 0\n",
    "        return float(re.sub(r'[^\\d.]', '', value))\n",
    "    return 0 if pd.isna(value) else value\n",
    "\n",
    "# Load and clean the Cost Comparison data\n",
    "def load_cost_data():\n",
    "    cost_data = pd.DataFrame([\n",
    "        ['Gemini 1.5 Flash', 1000000, 0.35, 0.70],\n",
    "        ['Gemini 2.0 Flash (Exp)', 1000000, 0, 0],\n",
    "        ['AWS Nova Pro', 300000, 0.0008, 0.0032],\n",
    "        ['AWS Nova Lite', 300000, 0.00006, 0.00024],\n",
    "        ['AWS Nova Micro', 300000, 0.000035, 0.00014],\n",
    "        ['Claude 3 Opus', 200000, 15.00, 75.00],\n",
    "        ['Claude 3 Sonnet', 200000, 3.00, 15.00],\n",
    "        ['Claude 3 Haiku', 200000, 0.25, 1.25],\n",
    "        ['Claude 3.5 Sonnet', 200000, 3, 15],\n",
    "        ['Claude 3.5 Haiku', 200000, 0.80, 4],\n",
    "        ['Qwen2.5-72b', 131000, 0.4, 0.75],\n",
    "        ['GPT-4 Turbo', 128000, 10.00, 30.00],\n",
    "        ['Gemini 1.5 Pro', 128000, 7, 21],\n",
    "        ['GPT4o', 128000, 5, 15],\n",
    "        ['GPT-4o mini', 128000, 0.15, 0.60],\n",
    "        ['OpenAI o1', 128000, 15, 60],\n",
    "        ['OpenAI o3-mini', 128000, 1.10, 4.40],\n",
    "        ['DeepSeek V3', 128000, 0.27, 1.1],\n",
    "        ['DeepSeek R1', 128000, 0.55, 2.19],\n",
    "        ['GPT 4.5', 128000, 25, 150],\n",
    "        ['OpenAI o1-mini', 64000, 1.10, 4.40],\n",
    "        ['GPT-4-32k', 32000, 60.00, 120.00],\n",
    "        ['Gemini Pro', 32000, 0.125, 0.375],\n",
    "        ['Mistral Medium', 32000, 2.7, 8.1],\n",
    "        ['Mistral Large', 32000, 8.00, 24.00],\n",
    "        ['GPT-3.5 Turbo', 16000, 0.5, 1.5],\n",
    "        ['Mistral Small', 16000, 2.00, 6.00],\n",
    "        ['GPT-4', 8000, 30.00, 60.00],\n",
    "        ['GPT-3.5 Turbo Instruct', 4000, 1.5, 2.00]\n",
    "    ], columns=['Models', 'Context Window', 'Input Cost / 1M tokens', 'Output Cost / 1M tokens'])\n",
    "    \n",
    "    # Calculate average cost\n",
    "    cost_data['Average Cost / 1M tokens'] = (cost_data['Input Cost / 1M tokens'] + cost_data['Output Cost / 1M tokens']) / 2\n",
    "    \n",
    "    return cost_data\n",
    "\n",
    "# Load and clean the General Model Performance data\n",
    "def load_performance_data():\n",
    "    perf_data = pd.DataFrame([\n",
    "        ['OpenAI o1', 0.8539, 0.918, 0.757, 0.924, 0.964, 0.6673, 0.893],\n",
    "        ['Claude 3.5 Sonnet', 0.845, 0.883, 0.65, 0.937, 0.783, 0.902, 0.916],\n",
    "        ['GPT-4o', 0.805, 0.887, 0.536, 0.902, 0.766, 0.8359, 0.905],\n",
    "        ['Llama 3.1 405b', 0.804, 0.886, 0.511, 0.89, 0.738, 0.885, 0.916],\n",
    "        ['OpenAI o1-mini', 0.8007, 0.852, 0.6, 0.924, 0.9, 0.6289, 0.899],\n",
    "        ['GPT-Turbo', 0.781, 0.865, 0.48, 0.871, 0.726, 0.86, 0.885],\n",
    "        ['OpenAI o1-mini', 0.775, 0.852, 0.6, 0.826, 0.924, 0.522, 0.899],\n",
    "        ['Claude 3 Opus', 0.767, 0.857, 0.504, 0.849, 0.601, 0.884, 0.907],\n",
    "        ['DeepSeek V3', 0.7624, 0.885, 0.591, 0.826, 0.902, 0.5723, 0.798],\n",
    "        ['GPT-4', 0.755, 0.864, 0.414, 0.866, 0.645, 0.883, 0.859],\n",
    "        ['Llama 3.1 70b', 0.755, 0.86, 0.467, 0.805, 0.68, 0.848, 0.869],\n",
    "        ['Llama 3.3 70b', 0.745, 0.86, 0.48, 0.884, 0.77, 0.775, 0.911],\n",
    "        ['Gemini 1.5 Pro', 0.741, 0.859, 0.462, 0.719, 0.677, 0.8435, 0.887],\n",
    "        ['Claude 3.5 Haiku', 0.683, 0.65, 0.416, 0.881, 0.694, 0.6, 0.856],\n",
    "        ['Gemini 1.5 Flash', 0.667, 0.789, 0.395, 0.715, 0.549, 0.7988, 0.755],\n",
    "        ['Claude 3 Haiku', 0.629, 0.752, 0.357, 0.759, 0.389, 0.7465, 0.717],\n",
    "        ['Llama 3.1 8b', 0.626, 0.73, 0.328, 0.726, 0.519, 0.761, 0.689],\n",
    "        ['GPT-3.5 Turbo', 0.592, 0.698, 0.308, 0.68, 0.341, 0.6441, 0.563],\n",
    "        ['Gemini 2.0 Flash', 0, 0.764, 0.621, 0, 0.897, 0, 0],\n",
    "        ['AWS Nova Micro', 0, 0.776, 0.4, 0.811, 0.693, 0.562, 0],\n",
    "        ['AWS Nova Lite', 0, 0.805, 0.42, 0.854, 0.733, 0.666, 0],\n",
    "        ['AWS Nova Pro', 0, 0.859, 0.469, 0.89, 0.766, 0.684, 0],\n",
    "        ['GPT-4o mini', 0, 0.82, 0.402, 0.872, 0.702, 0, 0.87],\n",
    "        ['Gemini Ultra', 0, 0.837, 0.357, 0, 0.532, 0, 0.79],\n",
    "        ['OpenAI o3-mini', 0, 0.869, 0.797, 0, 0.979, 0, 0.92],\n",
    "        ['Qwen2.5-72b', 0, 0.702, 0.49, 0.88, 0.85, 0.6131, 0],\n",
    "        ['OpenAI o3-mini', 0, 0.869, 0.707, 0, 0.979, 0, 0.92],\n",
    "        ['DeepSeek-R1', 0, 0.908, 0.715, 0, 0.973, 0, 0],\n",
    "        ['Grok-2', 0, 0.875, 0.56, 0.884, 0.761, 0, 0],\n",
    "        ['Grok-2 mini', 0, 0.862, 0.51, 0.857, 0.73, 0, 0]\n",
    "    ], columns=['Model', 'Average', 'MMLU(General)', 'GPQA(Reasoning)', 'HumanEval(Coding)', 'Math', 'BFCL(Tool Use)', 'MGSM(MUltilingual)'])\n",
    "    \n",
    "    return perf_data\n",
    "\n",
    "# Load and clean HumanEval data\n",
    "def load_humaneval_data():\n",
    "    humaneval_data = pd.DataFrame([\n",
    "        ['Claude 3.5 Sonnet', 0.937],\n",
    "        ['GPT-4o', 0.902],\n",
    "        ['AWS Nova Pro', 0.89],\n",
    "        ['Llama 3.1 405b', 0.89],\n",
    "        ['Grok-2', 0.884],\n",
    "        ['Claude 3.5 Haiku', 0.881],\n",
    "        ['Qwen2.5-70b', 0.88],\n",
    "        ['GPT-4o mini', 0.872],\n",
    "        ['GPT-Turbo', 0.871],\n",
    "        ['GPT-4', 0.866],\n",
    "        ['Grok-2 mini', 0.857],\n",
    "        ['AWS Nova Lite', 0.854],\n",
    "        ['Claude 3 Opus', 0.849],\n",
    "        ['OpenAI o1-mini', 0.826],\n",
    "        ['AWS Nova Micro', 0.811],\n",
    "        ['Llama 3.3 70b', 0.805],\n",
    "        ['Llama 3.1 70b', 0.805],\n",
    "        ['Llama 3.1 8b', 0.726],\n",
    "        ['Gemini 1.5 Pro', 0.719],\n",
    "        ['Gemini 1.5 Flash', 0.715],\n",
    "        ['GPT-3.5 Turbo', 0.68]\n",
    "    ], columns=['Model', 'HumanEval (0 shot)'])\n",
    "    \n",
    "    return humaneval_data\n",
    "\n",
    "# Load and clean Reasoning Dataset\n",
    "def load_reasoning_data():\n",
    "    reasoning_data = pd.DataFrame([\n",
    "        ['Claude 3.7 Sonnet (reasoner)', 0.848, 0, 0, 0, 0.861, 0.75, 0.932, 0.962, 0.8],\n",
    "        ['Grok 3 Beta', 0.846, 0, 0, 0, 0, 0.78, 0, 0, 0.933],\n",
    "        ['OpenAI o3-mini (High)', 0.797, 0.493, 0, 0, 0.795, 0, 0, 0.979, 0.873],\n",
    "        ['OpenAI o1', 0.78, 0.489, 0.735, 0.542, 0.877, 0.782, 0, 0.964, 0.833],\n",
    "        ['DeepSeek R1', 0.715, 0.492, 0, 0, 0, 0, 0.833, 0.973, 0.798],\n",
    "        ['Claude 3.7 Sonnet', 0.68, 0.703, 0.812, 0.584, 0.832, 0.718, 0.908, 0.822, 0.233],\n",
    "        ['Claude 3.5 Sonnet', 0.65, 0.49, 0.715, 0.488, 0.821, 0.704, 0.902, 0.78, 0.16]\n",
    "    ], columns=['Model', 'GPQA Diamond (Reasoning)', 'SWE-bench (Agent coding)', 'Tool Use(Retail)',\n",
    "                'Tool Use(Airline)', 'MMMLU(Multilingual)', 'MMMU(Visual)', 'IFEval', 'MATH 500', 'AIME 2024 (Math)'])\n",
    "    \n",
    "    return reasoning_data\n",
    "\n",
    "# Load and merge all data\n",
    "def prepare_combined_dataset():\n",
    "    cost_df = load_cost_data()\n",
    "    perf_df = load_performance_data()\n",
    "    humaneval_df = load_humaneval_data()\n",
    "    reasoning_df = load_reasoning_data()\n",
    "    \n",
    "    # Merge datasets on model name\n",
    "    # First, merge cost and performance\n",
    "    merged_df = pd.merge(cost_df, perf_df, left_on='Models', right_on='Model', how='outer')\n",
    "    \n",
    "    # Then merge HumanEval\n",
    "    merged_df = pd.merge(merged_df, humaneval_df, on='Model', how='outer')\n",
    "    \n",
    "    # Finally, merge reasoning data\n",
    "    merged_df = pd.merge(merged_df, reasoning_df, on='Model', how='outer')\n",
    "    \n",
    "    # Drop duplicate columns and handle missing values\n",
    "    if 'Model_x' in merged_df.columns:\n",
    "        merged_df.drop('Model_x', axis=1, inplace=True)\n",
    "    if 'Model_y' in merged_df.columns:\n",
    "        merged_df.drop('Model_y', axis=1, inplace=True)\n",
    "    \n",
    "    # Use model name as identifier\n",
    "    if 'Models' in merged_df.columns and 'Model' in merged_df.columns:\n",
    "        merged_df['Model'] = merged_df['Model'].fillna(merged_df['Models'])\n",
    "        merged_df.drop('Models', axis=1, inplace=True)\n",
    "    elif 'Models' in merged_df.columns and 'Model' not in merged_df.columns:\n",
    "        merged_df.rename(columns={'Models': 'Model'}, inplace=True)\n",
    "    \n",
    "    # Fill missing values\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Handle duplicate HumanEval values (keep the one from HumanEval dataset if available)\n",
    "    if 'HumanEval(Coding)' in merged_df.columns and 'HumanEval (0 shot)' in merged_df.columns:\n",
    "        merged_df['HumanEval'] = merged_df.apply(\n",
    "            lambda row: row['HumanEval (0 shot)'] if row['HumanEval (0 shot)'] > 0 else row['HumanEval(Coding)'],\n",
    "            axis=1\n",
    "        )\n",
    "        merged_df.drop(['HumanEval(Coding)', 'HumanEval (0 shot)'], axis=1, inplace=True)\n",
    "    elif 'HumanEval(Coding)' in merged_df.columns:\n",
    "        merged_df.rename(columns={'HumanEval(Coding)': 'HumanEval'}, inplace=True)\n",
    "    elif 'HumanEval (0 shot)' in merged_df.columns:\n",
    "        merged_df.rename(columns={'HumanEval (0 shot)': 'HumanEval'}, inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Build the SVM model\n",
    "def build_svm_model(data):\n",
    "    # Select features\n",
    "    feature_cols = [col for col in data.columns if col != 'Model' and not pd.api.types.is_string_dtype(data[col])]\n",
    "    X = data[feature_cols]\n",
    "    \n",
    "    # Standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Simple SVM model\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "    model.fit(X_scaled, data['Model'])\n",
    "    \n",
    "    return model, scaler, feature_cols\n",
    "\n",
    "# Build the neural network using TensorFlow\n",
    "def build_nn_model(data):\n",
    "    # Select features\n",
    "    feature_cols = [col for col in data.columns if col != 'Model' and not pd.api.types.is_string_dtype(data[col])]\n",
    "    X = data[feature_cols]\n",
    "    \n",
    "    # Standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Encode the target (model names)\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_encoded = encoder.fit_transform(data[['Model']])\n",
    "    \n",
    "    # Define model architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(y_encoded.shape[1], activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_scaled, y_encoded, epochs=200, batch_size=16, verbose=0)\n",
    "    \n",
    "    return model, scaler, encoder, feature_cols, history\n",
    "\n",
    "# Function for recommending models\n",
    "def recommend_models(user_inputs, svm_model, svm_scaler, tf_model, tf_scaler, tf_encoder, feature_cols, all_models_df):\n",
    "    # Prepare user input\n",
    "    user_vector = np.zeros(len(feature_cols))\n",
    "    \n",
    "    for i, feature in enumerate(feature_cols):\n",
    "        if feature in user_inputs:\n",
    "            user_vector[i] = user_inputs[feature]\n",
    "    \n",
    "    # Scale user input\n",
    "    svm_user_scaled = svm_scaler.transform([user_vector])\n",
    "    tf_user_scaled = tf_scaler.transform([user_vector])\n",
    "    \n",
    "    # Get SVM predictions\n",
    "    svm_probas = svm_model.predict_proba(svm_user_scaled)[0]\n",
    "    svm_indices = np.argsort(svm_probas)[::-1]\n",
    "    svm_classes = svm_model.classes_\n",
    "    svm_top5 = [(svm_classes[idx], svm_probas[idx]) for idx in svm_indices[:5]]\n",
    "    \n",
    "    # Get Neural Network predictions\n",
    "    tf_probas = tf_model.predict(tf_user_scaled, verbose=0)[0]\n",
    "    tf_top_indices = np.argsort(tf_probas)[::-1][:5]\n",
    "    tf_classes = tf_encoder.categories_[0]\n",
    "    tf_top5 = [(tf_classes[idx], tf_probas[idx]) for idx in tf_top_indices]\n",
    "    \n",
    "    # Combine predictions with weighted ensemble\n",
    "    combined_predictions = {}\n",
    "    \n",
    "    for model, score in svm_top5:\n",
    "        if model not in combined_predictions:\n",
    "            combined_predictions[model] = 0\n",
    "        combined_predictions[model] += score * 0.5\n",
    "    \n",
    "    for model, score in tf_top5:\n",
    "        if model not in combined_predictions:\n",
    "            combined_predictions[model] = 0\n",
    "        combined_predictions[model] += score * 0.5\n",
    "    \n",
    "    # Sort combined predictions\n",
    "    sorted_predictions = sorted(combined_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    top5_models = [model for model, _ in sorted_predictions[:5]]\n",
    "    \n",
    "    # Get details of recommended models\n",
    "    recommendations = all_models_df[all_models_df['Model'].isin(top5_models)]\n",
    "    \n",
    "    return svm_top5, tf_top5, sorted_predictions[:5], recommendations\n",
    "\n",
    "# Function to get user input through a simple interactive approach\n",
    "def get_user_input(feature_cols):\n",
    "    user_inputs = {}\n",
    "    \n",
    "    print(\"\\n--- LLM Recommendation System ---\\n\")\n",
    "    print(\"Please rate the importance of the following factors (0-10):\")\n",
    "    \n",
    "    # Context window size\n",
    "    if 'Context Window' in feature_cols:\n",
    "        context_window = int(input(\"Context window size (0=small, 10=very large): \"))\n",
    "        user_inputs['Context Window'] = context_window * 100000 / 10  # Scale to match data\n",
    "    \n",
    "    # Cost vs Performance\n",
    "    cost_importance = int(input(\"Cost sensitivity (0=cost doesn't matter, 10=very cost-sensitive): \"))\n",
    "    if 'Average Cost / 1M tokens' in feature_cols:\n",
    "        # Inverse relationship - higher cost sensitivity means lower cost tolerance\n",
    "        user_inputs['Average Cost / 1M tokens'] = (10 - cost_importance) * 5 / 10  # Scale to match data\n",
    "    \n",
    "    # Performance categories\n",
    "    print(\"\\nImportance of performance in different categories (0-10):\")\n",
    "    \n",
    "    if 'MMLU(General)' in feature_cols:\n",
    "        general_knowledge = int(input(\"General knowledge: \"))\n",
    "        user_inputs['MMLU(General)'] = general_knowledge / 10  # Scale to 0-1\n",
    "    \n",
    "    if 'GPQA(Reasoning)' in feature_cols:\n",
    "        reasoning = int(input(\"Reasoning abilities: \"))\n",
    "        user_inputs['GPQA(Reasoning)'] = reasoning / 10  # Scale to 0-1\n",
    "    \n",
    "    if 'HumanEval' in feature_cols:\n",
    "        coding = int(input(\"Coding capabilities: \"))\n",
    "        user_inputs['HumanEval'] = coding / 10  # Scale to 0-1\n",
    "    \n",
    "    if 'Math' in feature_cols:\n",
    "        math = int(input(\"Math skills: \"))\n",
    "        user_inputs['Math'] = math / 10  # Scale to 0-1\n",
    "    \n",
    "    if 'BFCL(Tool Use)' in feature_cols:\n",
    "        tool_use = int(input(\"Tool use capabilities: \"))\n",
    "        user_inputs['BFCL(Tool Use)'] = tool_use / 10  # Scale to 0-1\n",
    "    \n",
    "    if 'MGSM(MUltilingual)' in feature_cols:\n",
    "        multilingual = int(input(\"Multilingual capabilities: \"))\n",
    "        user_inputs['MGSM(MUltilingual)'] = multilingual / 10  # Scale to 0-1\n",
    "    \n",
    "    return user_inputs\n",
    "\n",
    "# Visualization function for recommendations\n",
    "def visualize_recommendations(recommendations, user_inputs, feature_cols):\n",
    "    # Prepare data for radar chart\n",
    "    categories = [feat for feat in feature_cols if feat in [\n",
    "        'MMLU(General)', 'GPQA(Reasoning)', 'HumanEval', 'Math', \n",
    "        'BFCL(Tool Use)', 'MGSM(MUltilingual)'\n",
    "    ]]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Performance radar chart for top models\n",
    "    ax = axs[0]\n",
    "    top_models = recommendations['Model'].tolist()[:5]\n",
    "    \n",
    "    # Number of variables\n",
    "    N = len(categories)\n",
    "    \n",
    "    # What will be the angle of each axis in the plot\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Draw one axis per variable and add labels\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([cat.split('(')[0] for cat in categories])\n",
    "    \n",
    "    # Draw y-axis lines and labels\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8'])\n",
    "    \n",
    "    # Plot data for each model\n",
    "    colors = ['b', 'g', 'r', 'c', 'm']\n",
    "    for i, model in enumerate(top_models[:5]):\n",
    "        model_data = recommendations[recommendations['Model'] == model]\n",
    "        values = [model_data[cat].values[0] for cat in categories]\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        # Plot values\n",
    "        ax.plot(angles, values, color=colors[i], linewidth=2, label=model)\n",
    "        ax.fill(angles, values, color=colors[i], alpha=0.1)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(-0.1, 1.1))\n",
    "    ax.set_title('Performance Comparison')\n",
    "    \n",
    "    # Cost vs Context Window chart\n",
    "    ax = axs[1]\n",
    "    for i, model in enumerate(top_models[:5]):\n",
    "        model_data = recommendations[recommendations['Model'] == model]\n",
    "        context = model_data['Context Window'].values[0] if 'Context Window' in model_data.columns else 0\n",
    "        cost = model_data['Average Cost / 1M tokens'].values[0] if 'Average Cost / 1M tokens' in model_data.columns else 0\n",
    "        \n",
    "        ax.scatter(context, cost, s=100, color=colors[i], label=model)\n",
    "    \n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel('Context Window Size')\n",
    "    ax.set_ylabel('Average Cost / 1M tokens')\n",
    "    ax.set_title('Cost vs Context Window')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Use log scale for better visualization\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('llm_recommendations.png')\n",
    "    \n",
    "    # Convert plot to bytes\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    \n",
    "    return buf\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Prepare dataset\n",
    "    print(\"Loading and preparing data...\")\n",
    "    all_data = prepare_combined_dataset()\n",
    "    \n",
    "    # Build SVM model\n",
    "    print(\"Building SVM model...\")\n",
    "    svm_model, svm_scaler, feature_cols = build_svm_model(all_data)\n",
    "    \n",
    "    # Build Neural Network model\n",
    "    print(\"Building Neural Network model...\")\n",
    "    tf_model, tf_scaler, tf_encoder, tf_feature_cols, history = build_nn_model(all_data)\n",
    "    \n",
    "    # Get user input\n",
    "    user_inputs = get_user_input(feature_cols)\n",
    "    \n",
    "    # Get recommendations\n",
    "    print(\"\\nGenerating recommendations...\")\n",
    "    svm_top5, tf_top5, ensemble_top5, recommendations = recommend_models(\n",
    "        user_inputs, svm_model, svm_scaler, tf_model, tf_scaler, tf_encoder, feature_cols, all_data\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n--- Model Recommendations ---\\n\")\n",
    "    \n",
    "    print(\"SVM Model Recommendations:\")\n",
    "    for model, score in svm_top5:\n",
    "        print(f\"- {model}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nNeural Network Recommendations:\")\n",
    "    for model, score in tf_top5:\n",
    "        print(f\"- {model}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nEnsemble Recommendations:\")\n",
    "    for model, score in ensemble_top5:\n",
    "        print(f\"- {model}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nDetails of recommended models:\")\n",
    "    relevant_cols = ['Model', 'Context Window', 'Average Cost / 1M tokens', 'Average',\n",
    "                     'MMLU(General)', 'GPQA(Reasoning)', 'HumanEval', 'Math', \n",
    "                     'BFCL(Tool Use)', 'MGSM(MUltilingual)']\n",
    "    \n",
    "    display_cols = [col for col in relevant_cols if col in recommendations.columns]\n",
    "    print(recommendations[display_cols].sort_values(by='Average', ascending=False).to_string(index=False))\n",
    "    \n",
    "    # Visualize recommendations\n",
    "    img_data = visualize_recommendations(recommendations, user_inputs, feature_cols)\n",
    "    \n",
    "    print(\"\\nRecommendation visualization saved as 'llm_recommendations.png'\")\n",
    "    \n",
    "    return svm_model, tf_model, svm_scaler, tf_scaler, tf_encoder, feature_cols, all_data\n",
    "\n",
    "# Run the system\n",
    "if __name__ == \"__main__\":\n",
    "    svm_model, tf_model, svm_scaler, tf_scaler, tf_encoder, feature_cols, all_data = main()\n",
    "\n",
    "# Create a simple Flask API for the LLM recommendation system\n",
    "def create_flask_api():\n",
    "    from flask import Flask, request, jsonify, send_file\n",
    "    import io\n",
    "    import base64\n",
    "    \n",
    "    app = Flask(__name__)\n",
    "    \n",
    "    # Load data and models\n",
    "    all_data = prepare_combined_dataset()\n",
    "    svm_model, svm_scaler, feature_cols = build_svm_model(all_data)\n",
    "    tf_model, tf_scaler, tf_encoder, _, _ = build_nn_model(all_data)\n",
    "    \n",
    "    @app.route('/recommend', methods=['POST'])\n",
    "    def recommend():\n",
    "        user_inputs = request.json\n",
    "        \n",
    "        svm_top5, tf_top5, ensemble_top5, recommendations = recommend_models(\n",
    "            user_inputs, svm_model, svm_scaler, tf_model, tf_scaler, tf_encoder, feature_cols, all_data\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        img_buffer = visualize_recommendations(recommendations, user_inputs, feature_cols)\n",
    "        img_str = base64.b64encode(img_buffer.getvalue()).decode('utf-8')\n",
    "        \n",
    "        # Prepare recommendations data\n",
    "        relevant_cols = ['Model', 'Context Window', 'Average Cost / 1M tokens', 'Average',\n",
    "                         'MMLU(General)', 'GPQA(Reasoning)', 'HumanEval', 'Math', \n",
    "                         'BFCL(Tool Use)', 'MGSM(MUltilingual)']\n",
    "        \n",
    "        display_cols = [col for col in relevant_cols if col in recommendations.columns]\n",
    "        recommendations_data = recommendations[display_cols].to_dict(orient='records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'svm_recommendations': svm_top5,\n",
    "            'nn_recommendations': tf_top5,\n",
    "            'ensemble_recommendations': ensemble_top5,\n",
    "            'details': recommendations_data,\n",
    "            'visualization': img_str\n",
    "        })\n",
    "    \n",
    "    @app.route('/', methods=['GET'])\n",
    "    def index():\n",
    "        return \"\"\"\n",
    "        <h1>LLM Recommendation API</h1>\n",
    "        <p>POST to /recommend with JSON data containing your preferences to get recommendations.</p>\n",
    "        \"\"\"\n",
    "    \n",
    "    return app\n",
    "\n",
    "# # Code to create a simple UI using Streamlit\n",
    "# def create_streamlit_ui():\n",
    "#     import streamlit as st\n",
    "    \n",
    "#     # Define the Streamlit app\n",
    "#     st.title(\"LLM Recommendation System\")\n",
    "    \n",
    "#     # Load data and models\n",
    "#     @st.cache_resource\n",
    "#     def load_models():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
